{"cells":[{"cell_type":"markdown","id":"fdcfe9a5","metadata":{"id":"fdcfe9a5"},"source":["Cell 1: Initial Setup and Imports (26-50)"]},{"cell_type":"code","execution_count":null,"id":"7e15af25","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29957,"status":"ok","timestamp":1755274293195,"user":{"displayName":"J.","userId":"08830157379463741241"},"user_tz":-480},"id":"7e15af25","outputId":"86a83b08-1e00-4d09-8e65-1f1b810d2211"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Using device: cuda\n","✓ INSTANCE event-based data files found\n","✓ Output directory: /content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Event_Based/experiment_results\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"INSTANCE_50_Experiments_Event_Based_Splits_Runs_26_to_50.ipynb\n","\n","This notebook runs experiments 26 to 50 with different event-based random splits\n","of the INSTANCE dataset.\n","\"\"\"\n","\n","# Import required libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","import os\n","import time\n","import random\n","import seaborn as sns\n","from tqdm import tqdm\n","from google.colab import drive\n","import pickle\n","\n","# Helper function to convert numpy types to Python types for JSON serialization\n","def numpy_to_python(obj):\n","    \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n","    if isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif isinstance(obj, np.integer):\n","        return int(obj)\n","    elif isinstance(obj, np.floating):\n","        return float(obj)\n","    elif isinstance(obj, dict):\n","        return {k: numpy_to_python(v) for k, v in obj.items()}\n","    elif isinstance(obj, list) or isinstance(obj, tuple):\n","        return [numpy_to_python(i) for i in obj]\n","    else:\n","        return obj\n","\n","# Define the range of split seeds for this notebook\n","START_SEED = 26\n","END_SEED = 50\n","\n","# Define the offset for random seeds to avoid overlap with seismogram-based split seeds\n","RANDOM_SEED_OFFSET = 50  # This will map split_seed 26→76, 27→77, etc.\n","\n","# Mount Google Drive if using Colab\n","drive.mount('/content/drive')\n","\n","# Configure environment\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')\n","\n","# Record start time\n","start_time = time.time()\n","\n","# Define paths to data files (UPDATED FOR INSTANCE)\n","base_dir = \"/content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Event_Based\"\n","all_data_file = os.path.join(base_dir, \"all_data.pt\")\n","all_labels_file = os.path.join(base_dir, \"all_labels.pt\")\n","split_info_file = os.path.join(base_dir, \"event_split_info.pkl\")\n","output_dir = os.path.join(base_dir, \"experiment_results\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Check if files exist\n","assert os.path.isfile(all_data_file), f\"Data file not found at {all_data_file}\"\n","assert os.path.isfile(all_labels_file), f\"Labels file not found at {all_labels_file}\"\n","assert os.path.isfile(split_info_file), f\"Split info file not found at {split_info_file}\"\n","\n","print(\"✓ INSTANCE event-based data files found\")\n","print(f\"✓ Output directory: {output_dir}\")"]},{"cell_type":"markdown","id":"8673afca","metadata":{"id":"8673afca"},"source":["Cell 2: Dataset and Model Classes"]},{"cell_type":"code","execution_count":null,"id":"b7b5c15a","metadata":{"id":"b7b5c15a"},"outputs":[],"source":["#------------------------------------------------------------------------------\n","# Dataset and Model Classes (FIXED FOR INSTANCE DATA FORMAT)\n","#------------------------------------------------------------------------------\n","\n","class EarthquakeDataset(Dataset):\n","    \"\"\"Dataset class for earthquake data.\"\"\"\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.labels[idx]\n","\n","class EarthquakeModel(nn.Module):\n","    \"\"\"MagNet architecture for earthquake magnitude estimation - ADAPTED FOR INSTANCE FORMAT.\"\"\"\n","    def __init__(self):\n","        super(EarthquakeModel, self).__init__()\n","        self.conv1 = nn.Conv1d(3, 64, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n","        self.maxpool = nn.MaxPool1d(4, padding=1)\n","        self.dropout = nn.Dropout(0.2)\n","        self.lstm = nn.LSTM(32, 100, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(200, 2)  # Output: [magnitude_prediction, log_variance]\n","\n","    def forward(self, x):\n","        # INSTANCE data format: [batch, channels, time_steps] - NO TRANSPOSE NEEDED\n","        # STEAD data format would be: [batch, time_steps, channels] - would need transpose\n","\n","        # Check input shape and print for debugging\n","        # print(f\"Input shape: {x.shape}\")  # The input format should be [batch, channels, time_steps] which would be (batch_size, 3, 3000)\n","\n","        # For INSTANCE: x is already [batch, channels, time_steps], so use directly\n","        # For STEAD: x would be [batch, time_steps, channels], so would need: x = x.transpose(1, 2)\n","\n","        # Since INSTANCE data is (362234, 3, 3000), each batch will be [batch, 3, 3000]\n","        # which is exactly what Conv1d expects: [batch, channels, time_steps]\n","\n","        # First conv block\n","        x = self.conv1(x)  # Input: [batch, 3, 3000] -> Output: [batch, 64, 3000]\n","        x = self.dropout(x)\n","        x = self.maxpool(x)  # Output: [batch, 64, 750]\n","\n","        # Second conv block\n","        x = self.conv2(x)  # Input: [batch, 64, 750] -> Output: [batch, 32, 750]\n","        x = self.dropout(x)\n","        x = self.maxpool(x)  # Output: [batch, 32, 187]\n","\n","        # Prepare for LSTM: [batch, time_steps, features]\n","        x = x.transpose(1, 2)  # [batch, 32, 187] -> [batch, 187, 32]\n","\n","        # LSTM layer\n","        x, _ = self.lstm(x)  # Input: [batch, 187, 32] -> Output: [batch, 187, 200]\n","\n","        # Get the last output of the LSTM\n","        x = x[:, -1, :]  # [batch, 187, 200] -> [batch, 200]\n","\n","        # Output layer with magnitude prediction and uncertainty\n","        x = self.fc(x)  # [batch, 200] -> [batch, 2]\n","\n","        return x"]},{"cell_type":"markdown","id":"48b8839c","metadata":{"id":"48b8839c"},"source":["Cell 3: Training Components"]},{"cell_type":"code","execution_count":null,"id":"be0e45de","metadata":{"id":"be0e45de"},"outputs":[],"source":["#------------------------------------------------------------------------------\n","# Training Components\n","#------------------------------------------------------------------------------\n","\n","class EarlyStopping:\n","    \"\"\"Early stopping to prevent overfitting.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, run_id=None,\n","                 split_num=None, model_seed=None):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = float('inf')\n","        self.delta = delta\n","        self.run_id = run_id\n","        self.split_num = split_num\n","        self.model_seed = model_seed\n","        self.best_model_path = None\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f})')\n","        self.best_model_path = os.path.join(\n","            output_dir, f'best_model_Run_{self.run_id}_split_{self.split_num}_seed_{self.model_seed}.pth'\n","        )\n","        torch.save(model.state_dict(), self.best_model_path)\n","        self.val_loss_min = val_loss\n","\n","def custom_loss(y_pred, y_true):\n","    \"\"\"\n","    Custom loss function combining prediction error and uncertainty.\n","\n","    This implements a negative log-likelihood loss with learned aleatoric uncertainty:\n","    L = 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n","\n","    where:\n","    - y_hat is the predicted magnitude\n","    - s is the log variance (uncertainty)\n","    - y_true is the true magnitude\n","\n","    This loss encourages the model to predict accurate magnitudes while\n","    also learning to estimate its own uncertainty.\n","    \"\"\"\n","    y_hat = y_pred[:, 0]    # Predicted magnitude\n","    s = y_pred[:, 1]        # Predicted log variance (uncertainty)\n","\n","    # Compute loss: 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n","    loss = 0.5 * torch.exp(-s) * (y_true - y_hat)**2 + 0.5 * s\n","\n","    return torch.mean(loss)"]},{"cell_type":"markdown","id":"b2ba6d37","metadata":{"id":"b2ba6d37"},"source":["Cell 4: Training and Evaluation Functions"]},{"cell_type":"code","execution_count":null,"id":"ebd60cc1","metadata":{"id":"ebd60cc1"},"outputs":[],"source":["#------------------------------------------------------------------------------\n","# Training and Evaluation Functions\n","#------------------------------------------------------------------------------\n","\n","def train_model(model, train_loader, val_loader, num_epochs=300, patience=5,\n","                run_id=None, split_num=None, model_seed=None, verbose=False):\n","    \"\"\"\n","    Train the model with early stopping and learning rate scheduling.\n","\n","    Args:\n","        model: The model to train\n","        train_loader: DataLoader for training data\n","        val_loader: DataLoader for validation data\n","        num_epochs: Maximum number of training epochs\n","        patience: Patience for early stopping\n","        run_id: Identifier for the experimental run\n","        split_num: Which data split is being used (0-49)\n","        model_seed: Random seed used for model initialization\n","        verbose: Whether to print detailed progress\n","\n","    Returns:\n","        Dictionary with training history and best model path\n","    \"\"\"\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='min', factor=np.sqrt(0.1),\n","        cooldown=0, patience=4, verbose=verbose, min_lr=0.5e-6\n","    )\n","\n","    early_stopping = EarlyStopping(\n","        patience=patience, verbose=verbose,\n","        run_id=run_id, split_num=split_num, model_seed=model_seed\n","    )\n","\n","    criterion = custom_loss\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(num_epochs):\n","        # Training phase\n","        model.train()\n","        running_loss = 0.0\n","        for data, target in train_loader:\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(data)\n","            loss = criterion(outputs, target)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        # Validation phase\n","        val_loss = 0.0\n","        model.eval()\n","        with torch.no_grad():\n","            for data, target in val_loader:\n","                data, target = data.to(device), target.to(device)\n","                outputs = model(data)\n","                loss = criterion(outputs, target)\n","                val_loss += loss.item()\n","\n","        # Calculate average losses\n","        val_loss /= len(val_loader)\n","        running_loss /= len(train_loader)\n","\n","        # Learning rate scheduling and early stopping\n","        scheduler.step(val_loss)\n","        early_stopping(val_loss, model)\n","\n","        if verbose:\n","            print(f'Epoch {epoch+1}, Loss: {running_loss:.4f}, '\n","                  f'Validation Loss: {val_loss:.4f}, '\n","                  f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n","\n","        train_losses.append(running_loss)\n","        val_losses.append(val_loss)\n","\n","        if early_stopping.early_stop:\n","            if verbose:\n","                print(f'Early stopping triggered at epoch {epoch+1}')\n","            break\n","\n","    return {\n","        'train_losses': train_losses,\n","        'val_losses': val_losses,\n","        'best_model_path': early_stopping.best_model_path\n","    }\n","\n","def estimate_uncertainty(model, data_loader, num_samples=50):\n","    \"\"\"\n","    Estimate model uncertainty using Monte Carlo dropout.\n","\n","    Args:\n","        model: Trained model\n","        data_loader: DataLoader for test data\n","        num_samples: Number of Monte Carlo samples\n","\n","    Returns:\n","        Tuple of (predictions, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty)\n","    \"\"\"\n","    model.eval()\n","\n","    # Enable dropout during inference for Monte Carlo sampling\n","    for m in model.modules():\n","        if isinstance(m, nn.Dropout):\n","            m.train()\n","\n","    predictions = []\n","    log_variances = []\n","\n","    with torch.no_grad():\n","        for _ in range(num_samples):\n","            batch_predictions = []\n","            batch_log_variances = []\n","            for data, _ in data_loader:\n","                data = data.to(device)\n","                output = model(data)\n","                batch_predictions.append(output[:, 0].cpu().numpy())\n","                batch_log_variances.append(output[:, 1].cpu().numpy())\n","            predictions.append(np.concatenate(batch_predictions))\n","            log_variances.append(np.concatenate(batch_log_variances))\n","\n","    predictions = np.array(predictions)\n","    log_variances = np.array(log_variances)\n","\n","    # Calculate mean prediction\n","    mean_prediction = np.mean(predictions, axis=0)\n","\n","    # Calculate mean of squared predictions\n","    yhat_squared_mean = np.mean(np.square(predictions), axis=0)\n","\n","    # Calculate aleatoric uncertainty from log variances\n","    aleatoric_uncertainty = np.mean(np.exp(log_variances), axis=0)\n","\n","    # Calculate epistemic uncertainty as standard deviation of predictions\n","    epistemic_uncertainty = np.std(predictions, axis=0)\n","\n","    # Calculate combined uncertainty\n","    combined_uncertainty = yhat_squared_mean - np.square(mean_prediction) + aleatoric_uncertainty\n","\n","    return mean_prediction, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty\n","\n","def evaluate_model(model_path, test_loader):\n","    \"\"\"\n","    Evaluate a trained model on test data.\n","\n","    Args:\n","        model_path: Path to the saved model weights\n","        test_loader: DataLoader for test data\n","\n","    Returns:\n","        Dictionary with evaluation metrics\n","    \"\"\"\n","    model = EarthquakeModel().to(device)\n","    model.load_state_dict(torch.load(model_path))\n","\n","    # Get predictions and uncertainties\n","    mean_pred, epistemic_unc, aleatoric_unc, combined_unc = estimate_uncertainty(model, test_loader)\n","\n","    # Get true values\n","    true_values = []\n","    for _, target in test_loader:\n","        true_values.append(target.numpy())\n","    true_values = np.concatenate(true_values)\n","\n","    # Calculate MAE\n","    mae = np.mean(np.abs(mean_pred - true_values))\n","\n","    return {\n","        'mae': float(mae),\n","        'mean_prediction': mean_pred,\n","        'true_values': true_values,\n","        'epistemic_uncertainty': epistemic_unc,\n","        'aleatoric_uncertainty': aleatoric_unc,\n","        'combined_uncertainty': combined_unc,\n","        'mean_epistemic_uncertainty': float(np.mean(epistemic_unc)),\n","        'mean_aleatoric_uncertainty': float(np.mean(aleatoric_unc)),\n","        'mean_combined_uncertainty': float(np.mean(combined_unc))\n","    }"]},{"cell_type":"markdown","id":"37e401a2","metadata":{"id":"37e401a2"},"source":["Cell 5: Experimental Functions"]},{"cell_type":"code","execution_count":null,"id":"6f73fe91","metadata":{"id":"6f73fe91"},"outputs":[],"source":["#------------------------------------------------------------------------------\n","# Experimental Functions\n","#------------------------------------------------------------------------------\n","\n","def set_seed(seed):\n","    \"\"\"Set random seeds for reproducibility.\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","def create_event_based_split(split_seed):\n","    \"\"\"\n","    Create a random event-based split with the specified seed\n","\n","    Args:\n","        split_seed: Random seed for the split\n","\n","    Returns:\n","        Dictionary with train, val, test data and labels\n","    \"\"\"\n","    # Load the data\n","    all_data = torch.load(all_data_file)\n","    all_labels = torch.load(all_labels_file)\n","\n","    # Load the split information\n","    with open(split_info_file, 'rb') as f:\n","        split_info = pickle.load(f)\n","\n","    unique_events = split_info['unique_events']\n","    event_indices = split_info['event_indices']\n","    train_ratio = split_info['train_ratio']\n","    val_ratio = split_info['val_ratio']\n","\n","    # Apply the offset to get a different random seed (51-75 instead of 1-25)\n","    random_seed = split_seed + RANDOM_SEED_OFFSET\n","\n","    # Set the seed for reproducibility using the new random seed\n","    print(f\"  Using random seed {random_seed} for split {split_seed}\")\n","    set_seed(random_seed)\n","\n","    # Create a shuffled copy of the unique events\n","    events_copy = unique_events.copy()\n","    random.shuffle(events_copy)\n","\n","    # Split events into train/val/test\n","    train_size = int(train_ratio * len(events_copy))\n","    val_size = int(val_ratio * len(events_copy))\n","\n","    train_events = events_copy[:train_size]\n","    val_events = events_copy[train_size:train_size + val_size]\n","    test_events = events_copy[train_size + val_size:]\n","\n","    # Collect indices for each split\n","    train_indices = np.concatenate([event_indices[event_id] for event_id in train_events])\n","    val_indices = np.concatenate([event_indices[event_id] for event_id in val_events])\n","    test_indices = np.concatenate([event_indices[event_id] for event_id in test_events])\n","\n","    # Extract data using the indices\n","    train_data = all_data[train_indices]\n","    train_labels = all_labels[train_indices]\n","\n","    val_data = all_data[val_indices]\n","    val_labels = all_labels[val_indices]\n","\n","    test_data = all_data[test_indices]\n","    test_labels = all_labels[test_indices]\n","\n","    return {\n","        'train_data': train_data,\n","        'train_labels': train_labels,\n","        'val_data': val_data,\n","        'val_labels': val_labels,\n","        'test_data': test_data,\n","        'test_labels': test_labels,\n","        'split_seed': split_seed,  # Keep the original split_seed for labeling (1-25)\n","        'random_seed': random_seed,  # Save the actual random seed used (51-75)\n","        'train_events': train_events,\n","        'val_events': val_events,\n","        'test_events': test_events\n","    }\n","\n","def run_experiment(split_seed, model_seeds, run_id):\n","    \"\"\"\n","    Run a complete experiment with multiple model initializations on a specific data split.\n","\n","    Args:\n","        split_seed: Random seed for the split\n","        model_seeds: List of random seeds for model initialization\n","        run_id: Identifier for this experiment run\n","\n","    Returns:\n","        Dictionary with experiment results\n","    \"\"\"\n","    print(f\"Running experiment with split seed {split_seed}\")\n","\n","    # Create the data split\n","    split_data = create_event_based_split(split_seed)\n","\n","    # Create datasets\n","    train_dataset = EarthquakeDataset(split_data['train_data'], split_data['train_labels'])\n","    val_dataset = EarthquakeDataset(split_data['val_data'], split_data['val_labels'])\n","    test_dataset = EarthquakeDataset(split_data['test_data'], split_data['test_labels'])\n","\n","    # Create dataloaders (UPDATED BATCH SIZE FOR LARGER INSTANCE DATASET)\n","    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=2)\n","    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=2)\n","    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=2)\n","\n","    # Log split sizes\n","    print(f\"  Train: {len(train_dataset)} samples from {len(split_data['train_events'])} events\")\n","    print(f\"  Validation: {len(val_dataset)} samples from {len(split_data['val_events'])} events\")\n","    print(f\"  Test: {len(test_dataset)} samples from {len(split_data['test_events'])} events\")\n","\n","    # Run experiments with multiple random initializations\n","    seed_results = []\n","\n","    for model_seed in model_seeds:\n","        print(f\"  Training with model seed {model_seed}\")\n","\n","        # Set random seed for model initialization\n","        set_seed(model_seed)\n","\n","        # Initialize the model\n","        model = EarthquakeModel().to(device)\n","\n","        # Train the model\n","        training_result = train_model(\n","            model, train_loader, val_loader,\n","            run_id=run_id, split_num=split_seed, model_seed=model_seed,\n","            verbose=False  # Set to True for detailed progress\n","        )\n","\n","        # Evaluate the model\n","        best_model_path = training_result['best_model_path']\n","        evaluation_result = evaluate_model(best_model_path, test_loader)\n","\n","        # Store results\n","        seed_results.append({\n","            'model_seed': model_seed,\n","            'training_history': {\n","                'train_losses': training_result['train_losses'],\n","                'val_losses': training_result['val_losses']\n","            },\n","            'evaluation': evaluation_result\n","        })\n","\n","        print(f\"  Seed {model_seed} - MAE: {evaluation_result['mae']:.4f}\")\n","\n","    # Find median performance\n","    sorted_results = sorted(seed_results, key=lambda x: x['evaluation']['mae'])\n","    median_result = sorted_results[len(model_seeds) // 2]\n","\n","    return {\n","        'split_seed': split_seed,\n","        'random_seed_used': split_seed + RANDOM_SEED_OFFSET,  # Save the actual random seed used\n","        'all_seed_results': seed_results,\n","        'median_mae': median_result['evaluation']['mae'],\n","        'median_model_seed': median_result['model_seed'],\n","        'median_aleatoric_uncertainty': median_result['evaluation']['mean_aleatoric_uncertainty'],\n","        'median_epistemic_uncertainty': median_result['evaluation']['mean_epistemic_uncertainty'],\n","        'median_combined_uncertainty': median_result['evaluation']['mean_combined_uncertainty'],\n","        'train_size': len(train_dataset),\n","        'val_size': len(val_dataset),\n","        'test_size': len(test_dataset),\n","        'train_events': len(split_data['train_events']),\n","        'val_events': len(split_data['val_events']),\n","        'test_events': len(split_data['test_events'])\n","    }"]},{"cell_type":"markdown","id":"b38d49a9","metadata":{"id":"b38d49a9"},"source":["Cell 6: Main Execution (26-50)"]},{"cell_type":"code","execution_count":null,"id":"703197ae","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"703197ae","outputId":"d0e73b9c-7710-43b5-9d1b-53b4696a3397"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting INSTANCE Event-Based Splitting Experiments 26-50\n","Expected: INSTANCE (avg 10.64 seismograms/event) should show MORE pronounced\n","differences than STEAD (avg 2.14 seismograms/event) between splitting methods\n","--------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:   0%|          | 0/25 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Running experiment with split seed 26\n","  Using random seed 76 for split 26\n","  Train: 250911 samples from 23821 events\n","  Validation: 37353 samples from 3403 events\n","  Test: 73970 samples from 6807 events\n","  Training with model seed 42\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["  Seed 42 - MAE: 0.2030\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2190\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2216\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2008\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1934\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:   4%|▍         | 1/25 [46:34<18:37:51, 2794.64s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 26 (using random seed 76)\n","Median MAE: 0.2030\n","Median Aleatoric Uncertainty: 0.0863\n","Median Epistemic Uncertainty: 0.0636\n","Median Combined Uncertainty: 0.0920\n","--------------------------------------------------\n","Running experiment with split seed 27\n","  Using random seed 77 for split 27\n","  Train: 255257 samples from 23821 events\n","  Validation: 34868 samples from 3403 events\n","  Test: 72109 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2132\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2182\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2076\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2012\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2052\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:   8%|▊         | 2/25 [1:29:26<17:01:05, 2663.73s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 27 (using random seed 77)\n","Median MAE: 0.2076\n","Median Aleatoric Uncertainty: 0.0932\n","Median Epistemic Uncertainty: 0.0749\n","Median Combined Uncertainty: 0.1008\n","--------------------------------------------------\n","Running experiment with split seed 28\n","  Using random seed 78 for split 28\n","  Train: 254581 samples from 23821 events\n","  Validation: 35483 samples from 3403 events\n","  Test: 72170 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1842\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1985\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1830\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1988\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2052\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  12%|█▏        | 3/25 [2:27:54<18:38:01, 3049.14s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 28 (using random seed 78)\n","Median MAE: 0.1985\n","Median Aleatoric Uncertainty: 0.0796\n","Median Epistemic Uncertainty: 0.0638\n","Median Combined Uncertainty: 0.0851\n","--------------------------------------------------\n","Running experiment with split seed 29\n","  Using random seed 79 for split 29\n","  Train: 254341 samples from 23821 events\n","  Validation: 35212 samples from 3403 events\n","  Test: 72681 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1962\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1934\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2022\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2011\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1923\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  16%|█▌        | 4/25 [3:25:02<18:39:31, 3198.63s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 29 (using random seed 79)\n","Median MAE: 0.1962\n","Median Aleatoric Uncertainty: 0.0822\n","Median Epistemic Uncertainty: 0.0642\n","Median Combined Uncertainty: 0.0879\n","--------------------------------------------------\n","Running experiment with split seed 30\n","  Using random seed 80 for split 30\n","  Train: 254847 samples from 23821 events\n","  Validation: 35728 samples from 3403 events\n","  Test: 71659 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2099\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1959\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2145\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1982\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1927\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  20%|██        | 5/25 [4:13:34<17:11:43, 3095.19s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 30 (using random seed 80)\n","Median MAE: 0.1982\n","Median Aleatoric Uncertainty: 0.0726\n","Median Epistemic Uncertainty: 0.0598\n","Median Combined Uncertainty: 0.0774\n","--------------------------------------------------\n","Running experiment with split seed 31\n","  Using random seed 81 for split 31\n","  Train: 251903 samples from 23821 events\n","  Validation: 35630 samples from 3403 events\n","  Test: 74701 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2076\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2040\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2092\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1973\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2094\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  24%|██▍       | 6/25 [5:05:17<16:21:03, 3098.09s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 31 (using random seed 81)\n","Median MAE: 0.2076\n","Median Aleatoric Uncertainty: 0.0874\n","Median Epistemic Uncertainty: 0.0682\n","Median Combined Uncertainty: 0.0936\n","--------------------------------------------------\n","Running experiment with split seed 32\n","  Using random seed 82 for split 32\n","  Train: 253444 samples from 23821 events\n","  Validation: 36798 samples from 3403 events\n","  Test: 71992 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2035\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2078\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1970\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1958\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2065\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  28%|██▊       | 7/25 [5:56:57<15:29:33, 3098.53s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 32 (using random seed 82)\n","Median MAE: 0.2035\n","Median Aleatoric Uncertainty: 0.0872\n","Median Epistemic Uncertainty: 0.0675\n","Median Combined Uncertainty: 0.0930\n","--------------------------------------------------\n","Running experiment with split seed 33\n","  Using random seed 83 for split 33\n","  Train: 253674 samples from 23821 events\n","  Validation: 36514 samples from 3403 events\n","  Test: 72046 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2332\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1992\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1898\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2050\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2131\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  32%|███▏      | 8/25 [6:44:01<14:13:09, 3011.13s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 33 (using random seed 83)\n","Median MAE: 0.2050\n","Median Aleatoric Uncertainty: 0.0798\n","Median Epistemic Uncertainty: 0.0670\n","Median Combined Uncertainty: 0.0858\n","--------------------------------------------------\n","Running experiment with split seed 34\n","  Using random seed 84 for split 34\n","  Train: 254220 samples from 23821 events\n","  Validation: 36517 samples from 3403 events\n","  Test: 71497 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1922\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2180\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2135\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2041\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2126\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  36%|███▌      | 9/25 [7:26:51<12:46:13, 2873.33s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 34 (using random seed 84)\n","Median MAE: 0.2126\n","Median Aleatoric Uncertainty: 0.0946\n","Median Epistemic Uncertainty: 0.0667\n","Median Combined Uncertainty: 0.1007\n","--------------------------------------------------\n","Running experiment with split seed 35\n","  Using random seed 85 for split 35\n","  Train: 255532 samples from 23821 events\n","  Validation: 35234 samples from 3403 events\n","  Test: 71468 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1977\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1944\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2054\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1892\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1959\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  40%|████      | 10/25 [8:22:47<12:35:37, 3022.47s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 35 (using random seed 85)\n","Median MAE: 0.1959\n","Median Aleatoric Uncertainty: 0.0800\n","Median Epistemic Uncertainty: 0.0645\n","Median Combined Uncertainty: 0.0857\n","--------------------------------------------------\n","Running experiment with split seed 36\n","  Using random seed 86 for split 36\n","  Train: 253018 samples from 23821 events\n","  Validation: 36081 samples from 3403 events\n","  Test: 73135 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2230\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2326\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2108\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2107\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2060\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  44%|████▍     | 11/25 [9:05:12<11:11:07, 2876.25s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 36 (using random seed 86)\n","Median MAE: 0.2108\n","Median Aleatoric Uncertainty: 0.0877\n","Median Epistemic Uncertainty: 0.0695\n","Median Combined Uncertainty: 0.0941\n","--------------------------------------------------\n","Running experiment with split seed 37\n","  Using random seed 87 for split 37\n","  Train: 252469 samples from 23821 events\n","  Validation: 35550 samples from 3403 events\n","  Test: 74215 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2068\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1990\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2176\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2100\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1966\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  48%|████▊     | 12/25 [9:51:34<10:16:58, 2847.60s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 37 (using random seed 87)\n","Median MAE: 0.2068\n","Median Aleatoric Uncertainty: 0.0799\n","Median Epistemic Uncertainty: 0.0614\n","Median Combined Uncertainty: 0.0851\n","--------------------------------------------------\n","Running experiment with split seed 38\n","  Using random seed 88 for split 38\n","  Train: 255108 samples from 23821 events\n","  Validation: 37348 samples from 3403 events\n","  Test: 69778 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2053\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2099\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1793\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2275\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1888\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  52%|█████▏    | 13/25 [10:44:54<9:50:51, 2954.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 38 (using random seed 88)\n","Median MAE: 0.2053\n","Median Aleatoric Uncertainty: 0.0858\n","Median Epistemic Uncertainty: 0.0744\n","Median Combined Uncertainty: 0.0932\n","--------------------------------------------------\n","Running experiment with split seed 39\n","  Using random seed 89 for split 39\n","  Train: 252038 samples from 23821 events\n","  Validation: 37024 samples from 3403 events\n","  Test: 73172 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2251\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1990\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2060\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2064\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2373\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  56%|█████▌    | 14/25 [11:30:58<8:51:03, 2896.69s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 39 (using random seed 89)\n","Median MAE: 0.2064\n","Median Aleatoric Uncertainty: 0.0835\n","Median Epistemic Uncertainty: 0.0705\n","Median Combined Uncertainty: 0.0901\n","--------------------------------------------------\n","Running experiment with split seed 40\n","  Using random seed 90 for split 40\n","  Train: 253128 samples from 23821 events\n","  Validation: 37012 samples from 3403 events\n","  Test: 72094 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2361\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2352\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2120\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1884\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2451\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  60%|██████    | 15/25 [12:12:29<7:42:26, 2774.61s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 40 (using random seed 90)\n","Median MAE: 0.2352\n","Median Aleatoric Uncertainty: 0.1181\n","Median Epistemic Uncertainty: 0.0878\n","Median Combined Uncertainty: 0.1284\n","--------------------------------------------------\n","Running experiment with split seed 41\n","  Using random seed 91 for split 41\n","  Train: 252216 samples from 23821 events\n","  Validation: 36746 samples from 3403 events\n","  Test: 73272 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2245\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1954\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2076\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2179\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2129\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  64%|██████▍   | 16/25 [13:01:12<7:02:51, 2819.03s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 41 (using random seed 91)\n","Median MAE: 0.2129\n","Median Aleatoric Uncertainty: 0.0899\n","Median Epistemic Uncertainty: 0.0696\n","Median Combined Uncertainty: 0.0960\n","--------------------------------------------------\n","Running experiment with split seed 42\n","  Using random seed 92 for split 42\n","  Train: 253708 samples from 23821 events\n","  Validation: 35694 samples from 3403 events\n","  Test: 72832 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2175\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2083\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1987\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1906\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2161\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  68%|██████▊   | 17/25 [13:47:09<6:13:23, 2800.42s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 42 (using random seed 92)\n","Median MAE: 0.2083\n","Median Aleatoric Uncertainty: 0.1001\n","Median Epistemic Uncertainty: 0.0628\n","Median Combined Uncertainty: 0.1055\n","--------------------------------------------------\n","Running experiment with split seed 43\n","  Using random seed 93 for split 43\n","  Train: 253471 samples from 23821 events\n","  Validation: 36644 samples from 3403 events\n","  Test: 72119 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1989\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2801\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2096\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2096\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2017\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  72%|███████▏  | 18/25 [14:26:00<5:10:17, 2659.58s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 43 (using random seed 93)\n","Median MAE: 0.2096\n","Median Aleatoric Uncertainty: 0.0909\n","Median Epistemic Uncertainty: 0.0720\n","Median Combined Uncertainty: 0.0982\n","--------------------------------------------------\n","Running experiment with split seed 44\n","  Using random seed 94 for split 44\n","  Train: 253156 samples from 23821 events\n","  Validation: 37185 samples from 3403 events\n","  Test: 71893 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1948\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2340\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2165\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2135\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1930\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  76%|███████▌  | 19/25 [15:12:57<4:30:40, 2706.80s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 44 (using random seed 94)\n","Median MAE: 0.2135\n","Median Aleatoric Uncertainty: 0.0972\n","Median Epistemic Uncertainty: 0.0701\n","Median Combined Uncertainty: 0.1037\n","--------------------------------------------------\n","Running experiment with split seed 45\n","  Using random seed 95 for split 45\n","  Train: 254017 samples from 23821 events\n","  Validation: 35507 samples from 3403 events\n","  Test: 72710 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2261\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2067\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2043\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2008\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2277\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  80%|████████  | 20/25 [15:57:04<3:44:03, 2688.78s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 45 (using random seed 95)\n","Median MAE: 0.2067\n","Median Aleatoric Uncertainty: 0.0884\n","Median Epistemic Uncertainty: 0.0645\n","Median Combined Uncertainty: 0.0938\n","--------------------------------------------------\n","Running experiment with split seed 46\n","  Using random seed 96 for split 46\n","  Train: 254754 samples from 23821 events\n","  Validation: 35219 samples from 3403 events\n","  Test: 72261 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1973\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1932\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2115\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2130\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2010\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  84%|████████▍ | 21/25 [16:48:03<3:06:40, 2800.04s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 46 (using random seed 96)\n","Median MAE: 0.2010\n","Median Aleatoric Uncertainty: 0.0759\n","Median Epistemic Uncertainty: 0.0712\n","Median Combined Uncertainty: 0.0827\n","--------------------------------------------------\n","Running experiment with split seed 47\n","  Using random seed 97 for split 47\n","  Train: 252508 samples from 23821 events\n","  Validation: 37034 samples from 3403 events\n","  Test: 72692 samples from 6807 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2341\n","  Training with model seed 123\n"]}],"source":["#------------------------------------------------------------------------------\n","# Main Execution\n","#------------------------------------------------------------------------------\n","\n","if __name__ == \"__main__\":\n","    # Define model initialization seeds (these stay fixed across all experiments)\n","    model_seeds = [42, 123, 256, 789, 1024]  # 5 different model initializations\n","\n","    # Define the specific split seeds for this notebook\n","    split_seeds = list(range(START_SEED, END_SEED + 1))\n","\n","    # Define results file for this range of experiments\n","    results_file = os.path.join(output_dir, f\"results_{START_SEED}_to_{END_SEED}.json\")\n","\n","    # Run experiments with the specified split seeds\n","    all_results = []\n","\n","    print(f\"Starting INSTANCE Event-Based Splitting Experiments {START_SEED}-{END_SEED}\")\n","    print(f\"Expected: INSTANCE (avg 10.64 seismograms/event) should show MORE pronounced\")\n","    print(f\"differences than STEAD (avg 2.14 seismograms/event) between splitting methods\")\n","    print(\"-\" * 80)\n","\n","    for i, split_seed in enumerate(tqdm(split_seeds, desc=f\"Running experiments {START_SEED}-{END_SEED}\")):\n","        # Calculate the global run ID (to maintain consistent naming with the original code)\n","        global_run_id = split_seed  # This keeps the same run_id as in the original code\n","\n","        # Run experiment for this split\n","        result = run_experiment(split_seed, model_seeds, global_run_id)\n","        all_results.append(result)\n","\n","        # Save results after each split\n","        with open(results_file, 'w') as f:\n","            # Convert numpy arrays to Python lists before serialization\n","            serializable_results = numpy_to_python(all_results)\n","            json.dump(serializable_results, f, indent=4)\n","\n","        print(f\"Completed experiment for split seed {split_seed} (using random seed {split_seed + RANDOM_SEED_OFFSET})\")\n","        print(f\"Median MAE: {result['median_mae']:.4f}\")\n","        print(f\"Median Aleatoric Uncertainty: {result['median_aleatoric_uncertainty']:.4f}\")\n","        print(f\"Median Epistemic Uncertainty: {result['median_epistemic_uncertainty']:.4f}\")\n","        print(f\"Median Combined Uncertainty: {result['median_combined_uncertainty']:.4f}\")\n","        print(\"-\" * 50)\n","\n","    # End timing\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(f\"\\nTotal execution time: {elapsed_time/60:.2f} minutes\")\n","\n","    print(f\"\\nINSTANCE Experiment batch {START_SEED}-{END_SEED} completed. Results saved in:\")\n","    print(f\"- {results_file}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}