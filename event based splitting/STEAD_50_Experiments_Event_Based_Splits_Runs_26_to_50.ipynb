{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"biGUs8wClsCA"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:   0%|          | 0/25 [00:00\u003c?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Running experiment with split seed 26\n","  Using random seed 76 for split 26\n","  Train: 204749 samples from 95825 events\n","  Validation: 29334 samples from 13689 events\n","  Test: 58347 samples from 27380 events\n","  Training with model seed 42\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["  Seed 42 - MAE: 0.1813\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2139\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1966\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2085\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1946\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:   4%|▍         | 1/25 [34:06\u003c13:38:27, 2046.13s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 26 (using random seed 76)\n","Median MAE: 0.1966\n","Median Aleatoric Uncertainty: 0.0790\n","Median Epistemic Uncertainty: 0.0597\n","Median Combined Uncertainty: 0.0844\n","--------------------------------------------------\n","Running experiment with split seed 27\n","  Using random seed 77 for split 27\n","  Train: 204578 samples from 95825 events\n","  Validation: 29294 samples from 13689 events\n","  Test: 58558 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2238\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1848\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2459\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1943\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2053\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:   8%|▊         | 2/25 [1:03:21\u003c11:58:44, 1874.99s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 27 (using random seed 77)\n","Median MAE: 0.2053\n","Median Aleatoric Uncertainty: 0.0935\n","Median Epistemic Uncertainty: 0.0557\n","Median Combined Uncertainty: 0.0983\n","--------------------------------------------------\n","Running experiment with split seed 28\n","  Using random seed 78 for split 28\n","  Train: 204133 samples from 95825 events\n","  Validation: 29436 samples from 13689 events\n","  Test: 58861 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2241\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1805\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2099\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2196\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2146\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  12%|█▏        | 3/25 [1:34:06\u003c11:22:28, 1861.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 28 (using random seed 78)\n","Median MAE: 0.2146\n","Median Aleatoric Uncertainty: 0.0981\n","Median Epistemic Uncertainty: 0.0575\n","Median Combined Uncertainty: 0.1032\n","--------------------------------------------------\n","Running experiment with split seed 29\n","  Using random seed 79 for split 29\n","  Train: 204327 samples from 95825 events\n","  Validation: 29311 samples from 13689 events\n","  Test: 58792 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1862\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1682\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1688\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1773\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2041\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  16%|█▌        | 4/25 [2:17:57\u003c12:37:50, 2165.28s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 29 (using random seed 79)\n","Median MAE: 0.1773\n","Median Aleatoric Uncertainty: 0.0674\n","Median Epistemic Uncertainty: 0.0543\n","Median Combined Uncertainty: 0.0725\n","--------------------------------------------------\n","Running experiment with split seed 30\n","  Using random seed 80 for split 30\n","  Train: 204353 samples from 95825 events\n","  Validation: 29235 samples from 13689 events\n","  Test: 58842 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1837\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2400\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1853\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1912\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2316\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  20%|██        | 5/25 [2:49:06\u003c11:26:10, 2058.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 30 (using random seed 80)\n","Median MAE: 0.1912\n","Median Aleatoric Uncertainty: 0.0776\n","Median Epistemic Uncertainty: 0.0553\n","Median Combined Uncertainty: 0.0823\n","--------------------------------------------------\n","Running experiment with split seed 31\n","  Using random seed 81 for split 31\n","  Train: 204283 samples from 95825 events\n","  Validation: 29659 samples from 13689 events\n","  Test: 58488 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2071\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1701\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1717\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2152\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1846\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  24%|██▍       | 6/25 [3:28:51\u003c11:26:58, 2169.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 31 (using random seed 81)\n","Median MAE: 0.1846\n","Median Aleatoric Uncertainty: 0.0748\n","Median Epistemic Uncertainty: 0.0499\n","Median Combined Uncertainty: 0.0787\n","--------------------------------------------------\n","Running experiment with split seed 32\n","  Using random seed 82 for split 32\n","  Train: 204149 samples from 95825 events\n","  Validation: 29330 samples from 13689 events\n","  Test: 58951 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2002\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1937\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2468\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2356\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1804\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  28%|██▊       | 7/25 [4:00:18\u003c10:23:05, 2076.95s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 32 (using random seed 82)\n","Median MAE: 0.2002\n","Median Aleatoric Uncertainty: 0.0820\n","Median Epistemic Uncertainty: 0.0539\n","Median Combined Uncertainty: 0.0863\n","--------------------------------------------------\n","Running experiment with split seed 33\n","  Using random seed 83 for split 33\n","  Train: 204456 samples from 95825 events\n","  Validation: 29280 samples from 13689 events\n","  Test: 58694 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2129\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2446\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1868\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1960\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2119\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  32%|███▏      | 8/25 [4:29:38\u003c9:19:57, 1976.32s/it] "]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 33 (using random seed 83)\n","Median MAE: 0.2119\n","Median Aleatoric Uncertainty: 0.1038\n","Median Epistemic Uncertainty: 0.0588\n","Median Combined Uncertainty: 0.1090\n","--------------------------------------------------\n","Running experiment with split seed 34\n","  Using random seed 84 for split 34\n","  Train: 204632 samples from 95825 events\n","  Validation: 29469 samples from 13689 events\n","  Test: 58329 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2040\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1725\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1845\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2290\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1794\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  36%|███▌      | 9/25 [5:08:11\u003c9:15:05, 2081.57s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 34 (using random seed 84)\n","Median MAE: 0.1845\n","Median Aleatoric Uncertainty: 0.0674\n","Median Epistemic Uncertainty: 0.0521\n","Median Combined Uncertainty: 0.0718\n","--------------------------------------------------\n","Running experiment with split seed 35\n","  Using random seed 85 for split 35\n","  Train: 204617 samples from 95825 events\n","  Validation: 29352 samples from 13689 events\n","  Test: 58461 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2701\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2182\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1973\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1772\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.1535\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  40%|████      | 10/25 [5:44:58\u003c8:50:01, 2120.09s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 35 (using random seed 85)\n","Median MAE: 0.1973\n","Median Aleatoric Uncertainty: 0.0736\n","Median Epistemic Uncertainty: 0.0544\n","Median Combined Uncertainty: 0.0783\n","--------------------------------------------------\n","Running experiment with split seed 36\n","  Using random seed 86 for split 36\n","  Train: 204587 samples from 95825 events\n","  Validation: 29349 samples from 13689 events\n","  Test: 58494 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1714\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1761\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2436\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1603\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2165\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  44%|████▍     | 11/25 [6:26:09\u003c8:39:45, 2227.51s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 36 (using random seed 86)\n","Median MAE: 0.1761\n","Median Aleatoric Uncertainty: 0.0694\n","Median Epistemic Uncertainty: 0.0529\n","Median Combined Uncertainty: 0.0742\n","--------------------------------------------------\n","Running experiment with split seed 37\n","  Using random seed 87 for split 37\n","  Train: 204813 samples from 95825 events\n","  Validation: 29175 samples from 13689 events\n","  Test: 58442 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1929\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2270\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1938\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2532\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2588\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  48%|████▊     | 12/25 [6:54:06\u003c7:26:20, 2060.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 37 (using random seed 87)\n","Median MAE: 0.2270\n","Median Aleatoric Uncertainty: 0.1116\n","Median Epistemic Uncertainty: 0.0608\n","Median Combined Uncertainty: 0.1173\n","--------------------------------------------------\n","Running experiment with split seed 38\n","  Using random seed 88 for split 38\n","  Train: 204986 samples from 95825 events\n","  Validation: 29013 samples from 13689 events\n","  Test: 58431 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1669\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1725\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2339\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1880\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2218\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  52%|█████▏    | 13/25 [7:31:45\u003c7:04:02, 2120.24s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 38 (using random seed 88)\n","Median MAE: 0.1880\n","Median Aleatoric Uncertainty: 0.0780\n","Median Epistemic Uncertainty: 0.0523\n","Median Combined Uncertainty: 0.0825\n","--------------------------------------------------\n","Running experiment with split seed 39\n","  Using random seed 89 for split 39\n","  Train: 204179 samples from 95825 events\n","  Validation: 29487 samples from 13689 events\n","  Test: 58764 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2149\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2039\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2134\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1743\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2324\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  56%|█████▌    | 14/25 [8:03:11\u003c6:15:45, 2049.59s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 39 (using random seed 89)\n","Median MAE: 0.2134\n","Median Aleatoric Uncertainty: 0.0948\n","Median Epistemic Uncertainty: 0.0582\n","Median Combined Uncertainty: 0.0995\n","--------------------------------------------------\n","Running experiment with split seed 40\n","  Using random seed 90 for split 40\n","  Train: 205056 samples from 95825 events\n","  Validation: 28852 samples from 13689 events\n","  Test: 58522 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1825\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2034\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1648\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2444\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2319\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  60%|██████    | 15/25 [8:37:18\u003c5:41:29, 2048.98s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 40 (using random seed 90)\n","Median MAE: 0.2034\n","Median Aleatoric Uncertainty: 0.0946\n","Median Epistemic Uncertainty: 0.0558\n","Median Combined Uncertainty: 0.0993\n","--------------------------------------------------\n","Running experiment with split seed 41\n","  Using random seed 91 for split 41\n","  Train: 205042 samples from 95825 events\n","  Validation: 29114 samples from 13689 events\n","  Test: 58274 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1978\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1991\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1986\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1899\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2736\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  64%|██████▍   | 16/25 [9:11:11\u003c5:06:36, 2044.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 41 (using random seed 91)\n","Median MAE: 0.1986\n","Median Aleatoric Uncertainty: 0.0854\n","Median Epistemic Uncertainty: 0.0560\n","Median Combined Uncertainty: 0.0902\n","--------------------------------------------------\n","Running experiment with split seed 42\n","  Using random seed 92 for split 42\n","  Train: 204572 samples from 95825 events\n","  Validation: 29275 samples from 13689 events\n","  Test: 58583 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1668\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1890\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1980\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1983\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2182\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  68%|██████▊   | 17/25 [9:47:56\u003c4:38:59, 2092.42s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 42 (using random seed 92)\n","Median MAE: 0.1980\n","Median Aleatoric Uncertainty: 0.0940\n","Median Epistemic Uncertainty: 0.0535\n","Median Combined Uncertainty: 0.0984\n","--------------------------------------------------\n","Running experiment with split seed 43\n","  Using random seed 93 for split 43\n","  Train: 204581 samples from 95825 events\n","  Validation: 29505 samples from 13689 events\n","  Test: 58344 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2187\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2433\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1867\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1970\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2203\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  72%|███████▏  | 18/25 [10:18:10\u003c3:54:22, 2008.87s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 43 (using random seed 93)\n","Median MAE: 0.2187\n","Median Aleatoric Uncertainty: 0.1002\n","Median Epistemic Uncertainty: 0.0551\n","Median Combined Uncertainty: 0.1047\n","--------------------------------------------------\n","Running experiment with split seed 44\n","  Using random seed 94 for split 44\n","  Train: 204816 samples from 95825 events\n","  Validation: 29349 samples from 13689 events\n","  Test: 58265 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2162\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2480\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2211\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2112\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2645\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  76%|███████▌  | 19/25 [10:43:47\u003c3:06:42, 1867.04s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 44 (using random seed 94)\n","Median MAE: 0.2211\n","Median Aleatoric Uncertainty: 0.0936\n","Median Epistemic Uncertainty: 0.0598\n","Median Combined Uncertainty: 0.0991\n","--------------------------------------------------\n","Running experiment with split seed 45\n","  Using random seed 95 for split 45\n","  Train: 204694 samples from 95825 events\n","  Validation: 29186 samples from 13689 events\n","  Test: 58550 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1625\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2106\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2376\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1984\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2373\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  80%|████████  | 20/25 [11:17:38\u003c2:39:41, 1916.40s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 45 (using random seed 95)\n","Median MAE: 0.2106\n","Median Aleatoric Uncertainty: 0.0785\n","Median Epistemic Uncertainty: 0.0542\n","Median Combined Uncertainty: 0.0831\n","--------------------------------------------------\n","Running experiment with split seed 46\n","  Using random seed 96 for split 46\n","  Train: 204461 samples from 95825 events\n","  Validation: 29276 samples from 13689 events\n","  Test: 58693 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1623\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2183\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2075\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1654\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2010\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  84%|████████▍ | 21/25 [11:58:13\u003c2:18:08, 2072.03s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 46 (using random seed 96)\n","Median MAE: 0.2010\n","Median Aleatoric Uncertainty: 0.1025\n","Median Epistemic Uncertainty: 0.0568\n","Median Combined Uncertainty: 0.1074\n","--------------------------------------------------\n","Running experiment with split seed 47\n","  Using random seed 97 for split 47\n","  Train: 204973 samples from 95825 events\n","  Validation: 28883 samples from 13689 events\n","  Test: 58574 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1852\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1681\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2164\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1972\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2076\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  88%|████████▊ | 22/25 [12:35:29\u003c1:46:03, 2121.19s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 47 (using random seed 97)\n","Median MAE: 0.1972\n","Median Aleatoric Uncertainty: 0.0889\n","Median Epistemic Uncertainty: 0.0551\n","Median Combined Uncertainty: 0.0935\n","--------------------------------------------------\n","Running experiment with split seed 48\n","  Using random seed 98 for split 48\n","  Train: 204512 samples from 95825 events\n","  Validation: 29269 samples from 13689 events\n","  Test: 58649 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1767\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.1920\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1985\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.1913\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2151\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  92%|█████████▏| 23/25 [13:11:45\u003c1:11:15, 2137.55s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 48 (using random seed 98)\n","Median MAE: 0.1920\n","Median Aleatoric Uncertainty: 0.0799\n","Median Epistemic Uncertainty: 0.0573\n","Median Combined Uncertainty: 0.0851\n","--------------------------------------------------\n","Running experiment with split seed 49\n","  Using random seed 99 for split 49\n","  Train: 204382 samples from 95825 events\n","  Validation: 29129 samples from 13689 events\n","  Test: 58919 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.2126\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2262\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.1911\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2153\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2094\n"]},{"name":"stderr","output_type":"stream","text":["\rRunning experiments 26-50:  96%|█████████▌| 24/25 [13:43:41\u003c34:31, 2071.22s/it]  "]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 49 (using random seed 99)\n","Median MAE: 0.2126\n","Median Aleatoric Uncertainty: 0.0963\n","Median Epistemic Uncertainty: 0.0566\n","Median Combined Uncertainty: 0.1010\n","--------------------------------------------------\n","Running experiment with split seed 50\n","  Using random seed 100 for split 50\n","  Train: 204782 samples from 95825 events\n","  Validation: 29144 samples from 13689 events\n","  Test: 58504 samples from 27380 events\n","  Training with model seed 42\n","  Seed 42 - MAE: 0.1925\n","  Training with model seed 123\n","  Seed 123 - MAE: 0.2113\n","  Training with model seed 256\n","  Seed 256 - MAE: 0.2079\n","  Training with model seed 789\n","  Seed 789 - MAE: 0.2128\n","  Training with model seed 1024\n","  Seed 1024 - MAE: 0.2287\n"]},{"name":"stderr","output_type":"stream","text":["Running experiments 26-50: 100%|██████████| 25/25 [14:14:05\u003c00:00, 2049.81s/it]"]},{"name":"stdout","output_type":"stream","text":["Completed experiment for split seed 50 (using random seed 100)\n","Median MAE: 0.2113\n","Median Aleatoric Uncertainty: 0.0917\n","Median Epistemic Uncertainty: 0.0543\n","Median Combined Uncertainty: 0.0962\n","--------------------------------------------------\n","\n","Total execution time: 854.11 minutes\n","\n","Experiment batch 26-50 completed. Results saved in:\n","- /content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/STEAD_Event_Based/experiment_results/results_26_to_50.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"STEAD_Experiments_Runs_26_to_50.ipynb\n","\n","This notebook runs experiments 26 to 50 with different event-based random splits\n","of the STEAD dataset.\n","\"\"\"\n","\n","# Import required libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","import os\n","import time\n","import random\n","import seaborn as sns\n","from tqdm import tqdm\n","from google.colab import drive\n","import pickle\n","\n","# Helper function to convert numpy types to Python types for JSON serialization\n","def numpy_to_python(obj):\n","    \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n","    if isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif isinstance(obj, np.integer):\n","        return int(obj)\n","    elif isinstance(obj, np.floating):\n","        return float(obj)\n","    elif isinstance(obj, dict):\n","        return {k: numpy_to_python(v) for k, v in obj.items()}\n","    elif isinstance(obj, list) or isinstance(obj, tuple):\n","        return [numpy_to_python(i) for i in obj]\n","    else:\n","        return obj\n","\n","# Define the range of split seeds for this notebook\n","START_SEED = 26\n","END_SEED = 50\n","\n","# Define the offset for random seeds to avoid overlap with seismogram-based split seeds\n","RANDOM_SEED_OFFSET = 50  # This will map split_seed 26→76, 27→77, etc.\n","\n","# Mount Google Drive if using Colab\n","drive.mount('/content/drive')\n","\n","# Configure environment\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')\n","\n","# Record start time\n","start_time = time.time()\n","\n","# Define paths to data files\n","base_dir = \"/content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/STEAD_Event_Based\"\n","all_data_file = os.path.join(base_dir, \"all_data.pt\")\n","all_labels_file = os.path.join(base_dir, \"all_labels.pt\")\n","split_info_file = os.path.join(base_dir, \"event_split_info.pkl\")\n","output_dir = os.path.join(base_dir, \"experiment_results\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Check if files exist\n","assert os.path.isfile(all_data_file), f\"Data file not found at {all_data_file}\"\n","assert os.path.isfile(all_labels_file), f\"Labels file not found at {all_labels_file}\"\n","assert os.path.isfile(split_info_file), f\"Split info file not found at {split_info_file}\"\n","\n","#------------------------------------------------------------------------------\n","# Dataset and Model Classes\n","#------------------------------------------------------------------------------\n","\n","class EarthquakeDataset(Dataset):\n","    \"\"\"Dataset class for earthquake data.\"\"\"\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.labels[idx]\n","\n","class EarthquakeModel(nn.Module):\n","    \"\"\"MagNet architecture for earthquake magnitude estimation.\"\"\"\n","    def __init__(self):\n","        super(EarthquakeModel, self).__init__()\n","        self.conv1 = nn.Conv1d(3, 64, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n","        self.maxpool = nn.MaxPool1d(4, padding=1)\n","        self.dropout = nn.Dropout(0.2)\n","        self.lstm = nn.LSTM(32, 100, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(200, 2)  # Output: [magnitude_prediction, log_variance]\n","\n","    def forward(self, x):\n","        # Input shape: [batch, time_steps, channels]\n","        # Convert to [batch, channels, time_steps] for conv layers\n","        x = x.transpose(1, 2)\n","\n","        # First conv block\n","        x = self.conv1(x)\n","        x = self.dropout(x)\n","        x = self.maxpool(x)\n","\n","        # Second conv block\n","        x = self.conv2(x)\n","        x = self.dropout(x)\n","        x = self.maxpool(x)\n","\n","        # Prepare for LSTM: [batch, time_steps, features]\n","        x = x.transpose(1, 2)\n","\n","        # LSTM layer\n","        x, _ = self.lstm(x)\n","\n","        # Get the last output of the LSTM\n","        x = x[:, -1, :]\n","\n","        # Output layer with magnitude prediction and uncertainty\n","        x = self.fc(x)\n","\n","        return x\n","\n","#------------------------------------------------------------------------------\n","# Training Components\n","#------------------------------------------------------------------------------\n","\n","class EarlyStopping:\n","    \"\"\"Early stopping to prevent overfitting.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, run_id=None,\n","                 split_num=None, model_seed=None):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = float('inf')\n","        self.delta = delta\n","        self.run_id = run_id\n","        self.split_num = split_num\n","        self.model_seed = model_seed\n","        self.best_model_path = None\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score \u003c self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter \u003e= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --\u003e {val_loss:.6f})')\n","        self.best_model_path = os.path.join(\n","            output_dir, f'best_model_Run_{self.run_id}_split_{self.split_num}_seed_{self.model_seed}.pth'\n","        )\n","        torch.save(model.state_dict(), self.best_model_path)\n","        self.val_loss_min = val_loss\n","\n","def custom_loss(y_pred, y_true):\n","    \"\"\"\n","    Custom loss function combining prediction error and uncertainty.\n","\n","    This implements a negative log-likelihood loss with learned aleatoric uncertainty:\n","    L = 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n","\n","    where:\n","    - y_hat is the predicted magnitude\n","    - s is the log variance (uncertainty)\n","    - y_true is the true magnitude\n","\n","    This loss encourages the model to predict accurate magnitudes while\n","    also learning to estimate its own uncertainty.\n","    \"\"\"\n","    y_hat = y_pred[:, 0]    # Predicted magnitude\n","    s = y_pred[:, 1]        # Predicted log variance (uncertainty)\n","\n","    # Compute loss: 0.5 * exp(-s) * (y_true - y_hat)^2 + 0.5 * s\n","    loss = 0.5 * torch.exp(-s) * (y_true - y_hat)**2 + 0.5 * s\n","\n","    return torch.mean(loss)\n","\n","#------------------------------------------------------------------------------\n","# Training and Evaluation Functions\n","#------------------------------------------------------------------------------\n","\n","def train_model(model, train_loader, val_loader, num_epochs=300, patience=5,\n","                run_id=None, split_num=None, model_seed=None, verbose=False):\n","    \"\"\"\n","    Train the model with early stopping and learning rate scheduling.\n","\n","    Args:\n","        model: The model to train\n","        train_loader: DataLoader for training data\n","        val_loader: DataLoader for validation data\n","        num_epochs: Maximum number of training epochs\n","        patience: Patience for early stopping\n","        run_id: Identifier for the experimental run\n","        split_num: Which data split is being used (0-49)\n","        model_seed: Random seed used for model initialization\n","        verbose: Whether to print detailed progress\n","\n","    Returns:\n","        Dictionary with training history and best model path\n","    \"\"\"\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='min', factor=np.sqrt(0.1),\n","        cooldown=0, patience=4, verbose=verbose, min_lr=0.5e-6\n","    )\n","\n","    early_stopping = EarlyStopping(\n","        patience=patience, verbose=verbose,\n","        run_id=run_id, split_num=split_num, model_seed=model_seed\n","    )\n","\n","    criterion = custom_loss\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(num_epochs):\n","        # Training phase\n","        model.train()\n","        running_loss = 0.0\n","        for data, target in train_loader:\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(data)\n","            loss = criterion(outputs, target)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        # Validation phase\n","        val_loss = 0.0\n","        model.eval()\n","        with torch.no_grad():\n","            for data, target in val_loader:\n","                data, target = data.to(device), target.to(device)\n","                outputs = model(data)\n","                loss = criterion(outputs, target)\n","                val_loss += loss.item()\n","\n","        # Calculate average losses\n","        val_loss /= len(val_loader)\n","        running_loss /= len(train_loader)\n","\n","        # Learning rate scheduling and early stopping\n","        scheduler.step(val_loss)\n","        early_stopping(val_loss, model)\n","\n","        if verbose:\n","            print(f'Epoch {epoch+1}, Loss: {running_loss:.4f}, '\n","                  f'Validation Loss: {val_loss:.4f}, '\n","                  f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n","\n","        train_losses.append(running_loss)\n","        val_losses.append(val_loss)\n","\n","        if early_stopping.early_stop:\n","            if verbose:\n","                print(f'Early stopping triggered at epoch {epoch+1}')\n","            break\n","\n","    return {\n","        'train_losses': train_losses,\n","        'val_losses': val_losses,\n","        'best_model_path': early_stopping.best_model_path\n","    }\n","\n","def estimate_uncertainty(model, data_loader, num_samples=50):\n","    \"\"\"\n","    Estimate model uncertainty using Monte Carlo dropout.\n","\n","    Args:\n","        model: Trained model\n","        data_loader: DataLoader for test data\n","        num_samples: Number of Monte Carlo samples\n","\n","    Returns:\n","        Tuple of (predictions, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty)\n","    \"\"\"\n","    model.eval()\n","\n","    # Enable dropout during inference for Monte Carlo sampling\n","    for m in model.modules():\n","        if isinstance(m, nn.Dropout):\n","            m.train()\n","\n","    predictions = []\n","    log_variances = []\n","\n","    with torch.no_grad():\n","        for _ in range(num_samples):\n","            batch_predictions = []\n","            batch_log_variances = []\n","            for data, _ in data_loader:\n","                data = data.to(device)\n","                output = model(data)\n","                batch_predictions.append(output[:, 0].cpu().numpy())\n","                batch_log_variances.append(output[:, 1].cpu().numpy())\n","            predictions.append(np.concatenate(batch_predictions))\n","            log_variances.append(np.concatenate(batch_log_variances))\n","\n","    predictions = np.array(predictions)\n","    log_variances = np.array(log_variances)\n","\n","    # Calculate mean prediction\n","    mean_prediction = np.mean(predictions, axis=0)\n","\n","    # Calculate mean of squared predictions\n","    yhat_squared_mean = np.mean(np.square(predictions), axis=0)\n","\n","    # Calculate aleatoric uncertainty from log variances\n","    aleatoric_uncertainty = np.mean(np.exp(log_variances), axis=0)\n","\n","    # Calculate epistemic uncertainty as standard deviation of predictions\n","    epistemic_uncertainty = np.std(predictions, axis=0)\n","\n","    # Calculate combined uncertainty\n","    combined_uncertainty = yhat_squared_mean - np.square(mean_prediction) + aleatoric_uncertainty\n","\n","    return mean_prediction, epistemic_uncertainty, aleatoric_uncertainty, combined_uncertainty\n","\n","def evaluate_model(model_path, test_loader):\n","    \"\"\"\n","    Evaluate a trained model on test data.\n","\n","    Args:\n","        model_path: Path to the saved model weights\n","        test_loader: DataLoader for test data\n","\n","    Returns:\n","        Dictionary with evaluation metrics\n","    \"\"\"\n","    model = EarthquakeModel().to(device)\n","    model.load_state_dict(torch.load(model_path))\n","\n","    # Get predictions and uncertainties\n","    mean_pred, epistemic_unc, aleatoric_unc, combined_unc = estimate_uncertainty(model, test_loader)\n","\n","    # Get true values\n","    true_values = []\n","    for _, target in test_loader:\n","        true_values.append(target.numpy())\n","    true_values = np.concatenate(true_values)\n","\n","    # Calculate MAE\n","    mae = np.mean(np.abs(mean_pred - true_values))\n","\n","    return {\n","        'mae': float(mae),\n","        'mean_prediction': mean_pred,\n","        'true_values': true_values,\n","        'epistemic_uncertainty': epistemic_unc,\n","        'aleatoric_uncertainty': aleatoric_unc,\n","        'combined_uncertainty': combined_unc,\n","        'mean_epistemic_uncertainty': float(np.mean(epistemic_unc)),\n","        'mean_aleatoric_uncertainty': float(np.mean(aleatoric_unc)),\n","        'mean_combined_uncertainty': float(np.mean(combined_unc))\n","    }\n","\n","#------------------------------------------------------------------------------\n","# Experimental Functions\n","#------------------------------------------------------------------------------\n","\n","def set_seed(seed):\n","    \"\"\"Set random seeds for reproducibility.\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","def create_event_based_split(split_seed):\n","    \"\"\"\n","    Create a random event-based split with the specified seed\n","\n","    Args:\n","        split_seed: Random seed for the split\n","\n","    Returns:\n","        Dictionary with train, val, test data and labels\n","    \"\"\"\n","    # Load the data\n","    all_data = torch.load(all_data_file)\n","    all_labels = torch.load(all_labels_file)\n","\n","    # Load the split information\n","    with open(split_info_file, 'rb') as f:\n","        split_info = pickle.load(f)\n","\n","    unique_events = split_info['unique_events']\n","    event_indices = split_info['event_indices']\n","    train_ratio = split_info['train_ratio']\n","    val_ratio = split_info['val_ratio']\n","\n","    # Apply the offset to get a different random seed (76-100 instead of 26-50)\n","    random_seed = split_seed + RANDOM_SEED_OFFSET\n","\n","    # Set the seed for reproducibility using the new random seed\n","    print(f\"  Using random seed {random_seed} for split {split_seed}\")\n","    set_seed(random_seed)\n","\n","    # Create a shuffled copy of the unique events\n","    events_copy = unique_events.copy()\n","    random.shuffle(events_copy)\n","\n","    # Split events into train/val/test\n","    train_size = int(train_ratio * len(events_copy))\n","    val_size = int(val_ratio * len(events_copy))\n","\n","    train_events = events_copy[:train_size]\n","    val_events = events_copy[train_size:train_size + val_size]\n","    test_events = events_copy[train_size + val_size:]\n","\n","    # Collect indices for each split\n","    train_indices = np.concatenate([event_indices[event_id] for event_id in train_events])\n","    val_indices = np.concatenate([event_indices[event_id] for event_id in val_events])\n","    test_indices = np.concatenate([event_indices[event_id] for event_id in test_events])\n","\n","    # Extract data using the indices\n","    train_data = all_data[train_indices]\n","    train_labels = all_labels[train_indices]\n","\n","    val_data = all_data[val_indices]\n","    val_labels = all_labels[val_indices]\n","\n","    test_data = all_data[test_indices]\n","    test_labels = all_labels[test_indices]\n","\n","    return {\n","        'train_data': train_data,\n","        'train_labels': train_labels,\n","        'val_data': val_data,\n","        'val_labels': val_labels,\n","        'test_data': test_data,\n","        'test_labels': test_labels,\n","        'split_seed': split_seed,  # Keep the original split_seed for labeling (26-50)\n","        'random_seed': random_seed,  # Save the actual random seed used (76-100)\n","        'train_events': train_events,\n","        'val_events': val_events,\n","        'test_events': test_events\n","    }\n","\n","def run_experiment(split_seed, model_seeds, run_id):\n","    \"\"\"\n","    Run a complete experiment with multiple model initializations on a specific data split.\n","\n","    Args:\n","        split_seed: Random seed for the split\n","        model_seeds: List of random seeds for model initialization\n","        run_id: Identifier for this experiment run\n","\n","    Returns:\n","        Dictionary with experiment results\n","    \"\"\"\n","    print(f\"Running experiment with split seed {split_seed}\")\n","\n","    # Create the data split\n","    split_data = create_event_based_split(split_seed)\n","\n","    # Create datasets\n","    train_dataset = EarthquakeDataset(split_data['train_data'], split_data['train_labels'])\n","    val_dataset = EarthquakeDataset(split_data['val_data'], split_data['val_labels'])\n","    test_dataset = EarthquakeDataset(split_data['test_data'], split_data['test_labels'])\n","\n","    # Create dataloaders\n","    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n","    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=2)\n","    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n","\n","    # Log split sizes\n","    print(f\"  Train: {len(train_dataset)} samples from {len(split_data['train_events'])} events\")\n","    print(f\"  Validation: {len(val_dataset)} samples from {len(split_data['val_events'])} events\")\n","    print(f\"  Test: {len(test_dataset)} samples from {len(split_data['test_events'])} events\")\n","\n","    # Run experiments with multiple random initializations\n","    seed_results = []\n","\n","    for model_seed in model_seeds:\n","        print(f\"  Training with model seed {model_seed}\")\n","\n","        # Set random seed for model initialization\n","        set_seed(model_seed)\n","\n","        # Initialize the model\n","        model = EarthquakeModel().to(device)\n","\n","        # Train the model\n","        training_result = train_model(\n","            model, train_loader, val_loader,\n","            run_id=run_id, split_num=split_seed, model_seed=model_seed,\n","            verbose=False  # Set to True for detailed progress\n","        )\n","\n","        # Evaluate the model\n","        best_model_path = training_result['best_model_path']\n","        evaluation_result = evaluate_model(best_model_path, test_loader)\n","\n","        # Store results\n","        seed_results.append({\n","            'model_seed': model_seed,\n","            'training_history': {\n","                'train_losses': training_result['train_losses'],\n","                'val_losses': training_result['val_losses']\n","            },\n","            'evaluation': evaluation_result\n","        })\n","\n","        print(f\"  Seed {model_seed} - MAE: {evaluation_result['mae']:.4f}\")\n","\n","    # Find median performance\n","    sorted_results = sorted(seed_results, key=lambda x: x['evaluation']['mae'])\n","    median_result = sorted_results[len(model_seeds) // 2]\n","\n","    return {\n","        'split_seed': split_seed,\n","        'random_seed_used': split_seed + RANDOM_SEED_OFFSET,  # Save the actual random seed used\n","        'all_seed_results': seed_results,\n","        'median_mae': median_result['evaluation']['mae'],\n","        'median_model_seed': median_result['model_seed'],\n","        'median_aleatoric_uncertainty': median_result['evaluation']['mean_aleatoric_uncertainty'],\n","        'median_epistemic_uncertainty': median_result['evaluation']['mean_epistemic_uncertainty'],\n","        'median_combined_uncertainty': median_result['evaluation']['mean_combined_uncertainty'],\n","        'train_size': len(train_dataset),\n","        'val_size': len(val_dataset),\n","        'test_size': len(test_dataset),\n","        'train_events': len(split_data['train_events']),\n","        'val_events': len(split_data['val_events']),\n","        'test_events': len(split_data['test_events'])\n","    }\n","\n","#------------------------------------------------------------------------------\n","# Main Execution\n","#------------------------------------------------------------------------------\n","\n","if __name__ == \"__main__\":\n","    # Define model initialization seeds (these stay fixed across all experiments)\n","    model_seeds = [42, 123, 256, 789, 1024]  # 5 different model initializations\n","\n","    # Define the specific split seeds for this notebook\n","    split_seeds = list(range(START_SEED, END_SEED + 1))\n","\n","    # Define results file for this range of experiments\n","    results_file = os.path.join(output_dir, f\"results_{START_SEED}_to_{END_SEED}.json\")\n","\n","    # Run experiments with the specified split seeds\n","    all_results = []\n","\n","    for i, split_seed in enumerate(tqdm(split_seeds, desc=f\"Running experiments {START_SEED}-{END_SEED}\")):\n","        # Calculate the global run ID (to maintain consistent naming with the original code)\n","        global_run_id = split_seed  # This keeps the same run_id as in the original code\n","\n","        # Run experiment for this split\n","        result = run_experiment(split_seed, model_seeds, global_run_id)\n","        all_results.append(result)\n","\n","        # Save results after each split\n","        with open(results_file, 'w') as f:\n","            # Convert numpy arrays to Python lists before serialization\n","            serializable_results = numpy_to_python(all_results)\n","            json.dump(serializable_results, f, indent=4)\n","\n","        print(f\"Completed experiment for split seed {split_seed} (using random seed {split_seed + RANDOM_SEED_OFFSET})\")\n","        print(f\"Median MAE: {result['median_mae']:.4f}\")\n","        print(f\"Median Aleatoric Uncertainty: {result['median_aleatoric_uncertainty']:.4f}\")\n","        print(f\"Median Epistemic Uncertainty: {result['median_epistemic_uncertainty']:.4f}\")\n","        print(f\"Median Combined Uncertainty: {result['median_combined_uncertainty']:.4f}\")\n","        print(\"-\" * 50)\n","\n","    # End timing\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(f\"\\nTotal execution time: {elapsed_time/60:.2f} minutes\")\n","\n","    print(f\"\\nExperiment batch {START_SEED}-{END_SEED} completed. Results saved in:\")\n","    print(f\"- {results_file}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNve1Gv+FVDW+kksMu+Ve5V","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}