{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oo18Q06vl2pp",
        "outputId": "ed0aa3bf-7979-4a0e-d01b-7f1dbb8d46ba"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"INSTANCE_Combine_Results.ipynb\n",
        "\n",
        "This notebook combines the results from both experiment batches and generates\n",
        "the final visualizations and statistics, just as if all 50 experiments had been\n",
        "run in a single notebook.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive if using Colab\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "base_dir = \"/content/drive/My Drive/2023-2024/UCL MSc in DSML/Term 3/MSc Project/Code/INSTANCE_Seismogram_Based\"\n",
        "output_dir = os.path.join(base_dir, \"experiment_results\")\n",
        "combined_results_file = os.path.join(output_dir, \"results_50_experiments.json\")\n",
        "\n",
        "# Helper function to convert numpy types to Python types for JSON serialization\n",
        "def numpy_to_python(obj):\n",
        "    \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n",
        "    if isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: numpy_to_python(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list) or isinstance(obj, tuple):\n",
        "        return [numpy_to_python(i) for i in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "def combine_results():\n",
        "    \"\"\"\n",
        "    Combine results from both experiment batches.\n",
        "\n",
        "    This function loads the two partial results files and combines them into a single\n",
        "    comprehensive results list, sorted by split_seed.\n",
        "    \"\"\"\n",
        "    # Define the two partial results files\n",
        "    batch1_file = os.path.join(output_dir, \"results_1_to_25.json\")\n",
        "    batch2_file = os.path.join(output_dir, \"results_26_to_50.json\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Load batch 1 results\n",
        "    if os.path.exists(batch1_file):\n",
        "        with open(batch1_file, 'r') as f:\n",
        "            batch1_results = json.load(f)\n",
        "            all_results.extend(batch1_results)\n",
        "    else:\n",
        "        print(f\"Warning: Results file {batch1_file} not found!\")\n",
        "\n",
        "    # Load batch 2 results\n",
        "    if os.path.exists(batch2_file):\n",
        "        with open(batch2_file, 'r') as f:\n",
        "            batch2_results = json.load(f)\n",
        "            all_results.extend(batch2_results)\n",
        "    else:\n",
        "        print(f\"Warning: Results file {batch2_file} not found!\")\n",
        "\n",
        "    # Sort by split_seed to ensure the final results are in the same order as the original code\n",
        "    all_results.sort(key=lambda x: x['split_seed'])\n",
        "\n",
        "    # Save the combined results\n",
        "    with open(combined_results_file, 'w') as f:\n",
        "        json.dump(all_results, f, indent=4)\n",
        "\n",
        "    print(f\"Combined {len(all_results)} experiment results.\")\n",
        "    return all_results\n",
        "\n",
        "def generate_visualizations(all_results):\n",
        "    \"\"\"\n",
        "    Generate the same visualizations as in the original code.\n",
        "\n",
        "    Args:\n",
        "        all_results: List of results from all experiments\n",
        "    \"\"\"\n",
        "    # Extract metrics\n",
        "    mae_values = [result['median_mae'] for result in all_results]\n",
        "    aleatoric_values = [result['median_aleatoric_uncertainty'] for result in all_results]\n",
        "    epistemic_values = [result['median_epistemic_uncertainty'] for result in all_results]\n",
        "    combined_values = [result['median_combined_uncertainty'] for result in all_results]\n",
        "\n",
        "    # Calculate statistics\n",
        "    mean_mae = np.mean(mae_values)\n",
        "    std_mae = np.std(mae_values)\n",
        "\n",
        "    # # Define fixed bins from 0.17 to 0.28 with intervals of 0.01\n",
        "    # fixed_bins = np.arange(0.17, 0.29, 0.01)  # Upper bound 0.29 to include 0.28\n",
        "\n",
        "    # Define fixed bins from 0.17 to 0.26 with intervals of 0.01\n",
        "    fixed_bins = np.arange(0.17, 0.26, 0.01)  # Upper bound 0.26 to include 0.25\n",
        "\n",
        "    # Plot MAE Distribution\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    n, bins, patches = plt.hist(mae_values, bins=fixed_bins, color='lightblue',\n",
        "                           alpha=0.6, edgecolor='black')\n",
        "\n",
        "    plt.axvline(mean_mae, color='red', linestyle='dashed', linewidth=2,\n",
        "                label=f'Mean = {mean_mae:.4f}')\n",
        "    plt.axvline(mean_mae + std_mae, color='green', linestyle='dotted', linewidth=2,\n",
        "                label=f'Mean + Std = {(mean_mae + std_mae):.4f}')\n",
        "    plt.axvline(mean_mae - std_mae, color='blue', linestyle='dotted', linewidth=2,\n",
        "                label=f'Mean - Std = {(mean_mae - std_mae):.4f}')\n",
        "\n",
        "    plt.xlabel('MAE', fontsize=16, fontweight='bold')\n",
        "    plt.ylabel('Number', fontsize=16, fontweight='bold')\n",
        "    plt.title('MAE Distribution over 50 Seismogram-Based Splitting Runs',\n",
        "              fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Set y-axis limit to 14\n",
        "    plt.ylim(0, 14)\n",
        "\n",
        "    plt.xticks(fixed_bins, fontsize=16)\n",
        "    plt.yticks(np.arange(0, 15, 2), fontsize=16)\n",
        "    plt.legend(fontsize=16)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'mae_distribution.png'))\n",
        "    plt.show()\n",
        "\n",
        "    # Plot uncertainty distributions\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(14, 24))\n",
        "\n",
        "    # Aleatoric Uncertainty\n",
        "    sns.histplot(aleatoric_values, bins=10, ax=axes[0], alpha=0.7,\n",
        "                edgecolor='black')\n",
        "    axes[0].axvline(np.mean(aleatoric_values), color='red', linestyle='--',\n",
        "                    label=f'Mean = {np.mean(aleatoric_values):.4f}')\n",
        "    axes[0].set_title('Aleatoric Uncertainty Distribution',\n",
        "                      fontsize=18, fontweight='bold')\n",
        "    axes[0].set_xlabel('Mean Aleatoric Uncertainty', fontsize=18, fontweight='bold')\n",
        "    axes[0].set_ylabel('Frequency', fontsize=18, fontweight='bold')\n",
        "    axes[0].tick_params(labelsize=18)\n",
        "    axes[0].legend(fontsize=18)\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Epistemic Uncertainty\n",
        "    sns.histplot(epistemic_values, bins=10, ax=axes[1], alpha=0.7,\n",
        "                edgecolor='black')\n",
        "    axes[1].axvline(np.mean(epistemic_values), color='red', linestyle='--',\n",
        "                    label=f'Mean = {np.mean(epistemic_values):.4f}')\n",
        "    axes[1].set_title('Epistemic Uncertainty Distribution',\n",
        "                      fontsize=18, fontweight='bold')\n",
        "    axes[1].set_xlabel('Mean Epistemic Uncertainty', fontsize=18, fontweight='bold')\n",
        "    axes[1].set_ylabel('Frequency', fontsize=18, fontweight='bold')\n",
        "    axes[1].tick_params(labelsize=18)\n",
        "    axes[1].legend(fontsize=18)\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # Combined Uncertainty\n",
        "    sns.histplot(combined_values, bins=10, ax=axes[2], alpha=0.7,\n",
        "                edgecolor='black')\n",
        "    axes[2].axvline(np.mean(combined_values), color='red', linestyle='--',\n",
        "                    label=f'Mean = {np.mean(combined_values):.4f}')\n",
        "    axes[2].set_title('Combined Uncertainty Distribution',\n",
        "                      fontsize=18, fontweight='bold')\n",
        "    axes[2].set_xlabel('Mean Combined Uncertainty', fontsize=18, fontweight='bold')\n",
        "    axes[2].set_ylabel('Frequency', fontsize=18, fontweight='bold')\n",
        "    axes[2].tick_params(labelsize=18)\n",
        "    axes[2].legend(fontsize=18)\n",
        "    axes[2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'uncertainty_distributions.png'))\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate overall statistics\n",
        "    print(\"\\nFinal Statistics:\")\n",
        "    print(f\"Mean MAE: {mean_mae:.4f}\")\n",
        "    print(f\"Standard Deviation of MAE: {std_mae:.4f}\")\n",
        "    print(f\"Minimum MAE: {min(mae_values):.4f}\")\n",
        "    print(f\"Maximum MAE: {max(mae_values):.4f}\")\n",
        "\n",
        "    # Save final statistics\n",
        "    with open(os.path.join(output_dir, \"final_statistics.json\"), 'w') as f:\n",
        "        json.dump(numpy_to_python({\n",
        "            'mean_mae': mean_mae,\n",
        "            'std_mae': std_mae,\n",
        "            'min_mae': min(mae_values),\n",
        "            'max_mae': max(mae_values),\n",
        "            'mean_aleatoric_uncertainty': np.mean(aleatoric_values),\n",
        "            'mean_epistemic_uncertainty': np.mean(epistemic_values),\n",
        "            'mean_combined_uncertainty': np.mean(combined_values)\n",
        "        }), f, indent=4)\n",
        "\n",
        "    print(\"\\nVisualization completed. Results saved in:\")\n",
        "    print(f\"- {combined_results_file}\")\n",
        "    print(f\"- {os.path.join(output_dir, 'mae_distribution.png')}\")\n",
        "    print(f\"- {os.path.join(output_dir, 'uncertainty_distributions.png')}\")\n",
        "    print(f\"- {os.path.join(output_dir, 'final_statistics.json')}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting results combination process...\")\n",
        "    all_results = combine_results()\n",
        "\n",
        "    if len(all_results) == 50:\n",
        "        print(\"Successfully collected all 50 experiment results.\")\n",
        "        generate_visualizations(all_results)\n",
        "    else:\n",
        "        print(f\"Warning: Only found {len(all_results)} experiment results instead of 50.\")\n",
        "        user_input = input(\"Do you want to proceed with generating visualizations anyway? (y/n): \")\n",
        "        if user_input.lower() == 'y':\n",
        "            generate_visualizations(all_results)\n",
        "        else:\n",
        "            print(\"Visualization canceled. Please check that all experiment notebooks have completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3vg-3BM1uMN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
